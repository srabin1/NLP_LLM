{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff713495",
   "metadata": {},
   "source": [
    "# Setting up API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59db7445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.40.2-py3-none-any.whl (360 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.5.0-cp39-none-win_amd64.whl (191 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sanaz\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.4)\n",
      "Installing collected packages: h11, pydantic-core, httpcore, annotated-types, pydantic, jiter, httpx, distro, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.2 pydantic-2.8.2 pydantic-core-2.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dfb5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53827b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "270b62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c24e0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e9aee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa48749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f914bdb",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1e2ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    #openai.api_key = 'your_openai_api_key_here'\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # Adjust the model as needed.\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=10,  # Adjust this based on how long you expect the response to be.\n",
    "        temperature=0.7  # This controls how creative the response will be. Lower is more deterministic.\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dafe62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompot to pass to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "658166d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "852f64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a small village nestled in the heart of\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5132da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e656d",
   "metadata": {},
   "source": [
    "## Customizing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e95d95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_tokens):\n",
    "    #openai.api_key = 'your_openai_api_key_here'\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # Adjust the model as needed.\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = max_tokens,  # Adjust this based on how long you expect the response to be.\n",
    "        temperature = 0.7  # This controls how creative the response will be. Lower is more deterministic.\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dc984b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land filled with\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 5)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "390a4238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a kingdom far, far away, there lived a wise and benevolent king named Ethelred\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 20)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8246b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a kingdom far, far away, there lived a wise old king named Eldred. King Eldred was known throughout the land for his just and fair rule. His wisdom was sought by many, and his kingdom was one of peace and prosperity.\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 50)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c523ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_tokens, temperature):\n",
    "    #openai.api_key = 'your_openai_api_key_here'\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # Adjust the model as needed.\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = max_tokens,  # Adjust this based on how long you expect the response to be.\n",
    "        temperature = temperature  # This controls how creative the response will be. Lower is more deterministic.\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9333dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land far, far away, there was a kingdom known as Eldoria. Eldoria was\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 20, 0)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82e15a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a kingdom far, far away, there was a little girl named Ella. Ella was not an\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 20, 1)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "613a0c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land far, far away, there was a kingdom known as Eldoria. Eldoria was a prosperous kingdom, known for its lush landscapes, towering mountains, and sparkling rivers. The people of Eldoria were kind and hardworking, always ready\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 50, 0)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70e2d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land far far away, there lived a gentle and generous king named Eirik. This king was much loved by his subjects, not only because of his kindness but also for his wisdom and bravery. His kingdom, Bathoshire, was\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, 50, 1)\n",
    "print(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8b67c",
   "metadata": {},
   "source": [
    "## Summarising Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c506a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "      model = \"gpt-4\",\n",
    "      messages =[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"A flying saucer seen by a guest house, a 7ft alien-like figure coming out of a hedge and a \\\"cigar-shaped\\\" UFO near a school yard.\\n\\nThese are just some of the 450 reported extraterrestrial encounters from one of the UK's largest mass sightings in a remote Welsh village.\\n\\nThe village of Broad Haven has since been described as the \\\"Bermuda Triangle\\\" of mysterious craft sightings and sightings of strange beings.\\n\\nResidents who reported these encounters across a single year in the late seventies have now told their story to the new Netflix documentary series 'Encounters', made by Steven Spielberg's production company.\\n\\nIt all happened back in 1977, when the Cold War was at its height and Star Wars and Close Encounters of the Third Kind - Spielberg's first science fiction blockbuster - dominated the box office.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"flying saucer, guest house, 7ft alien-like figure, hedge, cigar-shaped UFO, school yard, extraterrestrial encounters, UK, mass sightings, remote Welsh village, Broad Haven, Bermuda Triangle, mysterious craft sightings, strange beings, residents, single year, late seventies, Netflix documentary series, Steven Spielberg, production company, 1977, Cold War, Star Wars, Close Encounters of the Third Kind, science fiction blockbuster, box office.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Each April, in the village of Maeliya in northwest Sri Lanka, Pinchal Weldurelage Siriwardene gathers his community under the shade of a large banyan tree. The tree overlooks a human-made body of water called a wewa – meaning reservoir or \\\"tank\\\" in Sinhala. The wewa stretches out besides the village's rice paddies for 175-acres (708,200 sq m) and is filled with the rainwater of preceding months.    \\n\\nSiriwardene, the 76-year-old secretary of the village's agrarian committee, has a tightly-guarded ritual to perform. By boiling coconut milk on an open hearth beside the tank, he will seek blessings for a prosperous harvest from the deities residing in the tree. \\\"It's only after that we open the sluice gate to water the rice fields,\\\" he told me when I visited on a scorching mid-April afternoon.\\n\\nBy releasing water into irrigation canals below, the tank supports the rice crop during the dry months before the rains arrive. For nearly two millennia, lake-like water bodies such as this have helped generations of farmers cultivate their fields. An old Sinhala phrase, \\\"wewai dagabai gamai pansalai\\\", even reflects the technology's centrality to village life; meaning \\\"tank, pagoda, village and temple\\\".\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"April, Maeliya, northwest Sri Lanka, Pinchal Weldurelage Siriwardene, banyan tree, wewa, reservoir, tank, Sinhala, rice paddies, 175-acres, 708,200 sq m, rainwater, agrarian committee, coconut milk, open hearth, blessings, prosperous harvest, deities, sluice gate, rice fields, irrigation canals, dry months, rains, lake-like water bodies, farmers, cultivate, Sinhala phrase, technology, village life, pagoda, temple.\"\n",
    "        }, \n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt\n",
    "        }\n",
    "      ],\n",
    "      temperature = 0.5,\n",
    "      max_tokens = 256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ed97f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "67f98014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Master Reef Guide, Kirsty Whitman, snorkel mask, male manta ray, female, potential mate, animated presentation, snorkelling safari, encounter, magical, current, undersea ballet, precious seconds.'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarizer(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e748a",
   "metadata": {},
   "source": [
    "## Poetic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "73238239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poetic_chatbot(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4\",\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a poetic chatbot.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"When was Google founded?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Which country has the youngest president?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature = 1,\n",
    "        max_tokens = 256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "beeeef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In realms of past, so rich, so vague, \\nA tale unfolds from ancient age.\\nAround 8000 BC, in realms of Fertile Crescent,\\nThe art of cheese making made its lovely presence.\\n\\nIn vessels pottery, there milk was stored,\\nCurled by bacteria, a transformation adored.\\nThus was born cheese, a culinary delight,\\nSavoring our taste buds, every day and every night.'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"When was cheese first made?\"\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "278b9de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI of verse and rhyme, with knowledge deep but not of time, I lack the foresight, can't see the course, on 365DataScience's upcoming discourse. For queries like this, you must adjourn, to their website directly, there you'll learn.\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the next course to be uploaded to 365DataScience?\"\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4f353",
   "metadata": {},
   "source": [
    "## GPT data can be outdated but we can use langchain to train it with our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa362409",
   "metadata": {},
   "source": [
    "## LLM --> LangChain --> Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e27b8",
   "metadata": {},
   "source": [
    "## LangChaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24bc6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "867ea0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62a61d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2586e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://365datascience.com/upcoming-courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50740551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. What is 365 Data Science?\n",
      "365 Data Science is a platform that offers a variety of data science courses, career tracks, and resources for individuals looking to enhance their skills and knowledge in the field of data science. \n",
      "\n",
      "2. What can I learn on 365 Data Science?\n",
      "On 365 Data Science, you can learn various data science courses, career tracks, and projects, as well as access resources such as course notes, templates, career guides, and practice exams. \n",
      "\n",
      "3. Are there any upcoming courses on 365 Data Science?\n",
      "Yes, there are upcoming courses on 365 Data Science. The upcoming course mentioned on the platform is \"Intro to AI\" with instructor Ned Krastev, which will be launched in August 2024. \n",
      "\n",
      "4. Can I get certificates for completing courses on 365 Data Science?\n",
      "Yes, you can receive a Career Track Certificate or a Course Certificate upon completing a course on 365 Data Science. \n",
      "\n",
      "5. Is there a pricing plan for businesses on 365 Data Science?\n",
      "Yes, there is a team plan for businesses on 365 Data Science, as well as an option for live training. \n",
      "\n",
      "6. What is the \"Intro to AI\" course about?\n",
      "The \"Intro to AI\" course on \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Step 1: Fetch content from a URL\n",
    "def fetch_content_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.text\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        return soup.get_text()  # Extract text content from the page\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#url = \"https://365datascience.com/upcoming-courses\"\n",
    "content = fetch_content_from_url(url)\n",
    "\n",
    "# Step 2: Initialize OpenAI and LangChain\n",
    "openai = OpenAI(api_key = openai.api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a knowledgeable assistant. I have provided the following content:\n",
    "\n",
    "{content}\n",
    "\n",
    "Based on the above content, answer the user's questions.\n",
    "\"\"\"\n",
    "\n",
    "def create_chain(content):\n",
    "    prompt = PromptTemplate(input_variables=[\"content\"], template=prompt_template)\n",
    "    chain = LLMChain(llm=openai, prompt=prompt)\n",
    "    return chain\n",
    "\n",
    "# Step 3: Create a chatbot function\n",
    "def chatbot(chain, user_input):\n",
    "    response = chain.run({\"content\": content})\n",
    "    return response\n",
    "\n",
    "# Step 4: Example usage\n",
    "if content:\n",
    "    chain = create_chain(content)\n",
    "    user_input = \"What is the main topic of the page?\"\n",
    "    response = chatbot(chain, user_input)\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"Failed to retrieve content from the URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ff946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
